{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd14163-5386-47d9-af30-107ef5d6cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Hyper Parameter Tuning ####################\n",
    "\n",
    "#Step-1: Reading the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(r'~/Desktop/HealthCare_Insurance_Segmentation/Datasets/FE_data.csv')\n",
    "\n",
    "#Step-2: Train and Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X=df.iloc[:,0:-1]\n",
    "Y=df[\"Renewal\"]\n",
    "\n",
    "#Considering the 30% for test dataset\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "##### Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "par={\"n_estimators\":[100,200,300,400],\"max_depth\":[5,10,20,30,50],\"min_samples_split\":[5,10,20]}\n",
    "a=RandomForestClassifier()\n",
    "m1=GridSearchCV(a,param_grid=par,cv=5)\n",
    "m1.fit(X_train,Y_train)\n",
    "gds=m1.best_estimator_\n",
    "GS=gds.fit(X_train,Y_train)\n",
    "\n",
    "# Evaluation on Training Data\n",
    "print(confusion_matrix(Y_train, GS.predict(X_train)))\n",
    "GS_train_acc = accuracy_score(GS.predict(X_train),Y_train)\n",
    "print(\"Grid Search Train Accuracy: \",\"{:.2%}\".format(GS_train_acc))\n",
    "\n",
    "# Evaluation on Testing Data\n",
    "print(confusion_matrix(Y_test,GS.predict(X_test)))\n",
    "GS_test_acc = accuracy_score(GS.predict(X_test),Y_test)\n",
    "print(\"Grid Search Test Accuracy: \",\"{:.2%}\".format(GS_test_acc))\n",
    "\n",
    "\n",
    "'''Since GridSearch-Cross_Validation uses K-Fold \n",
    "there is no need to create seperate Train and Test data,\n",
    "Predictors and Target of full dataset will be passed'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#decalring a model instance\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "lr = LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#creating list of models\n",
    "model_all = [knn , svm , rf , dt , lr , gnb]\n",
    "\n",
    "#decalring parameters for hyper tuning\n",
    "param1 = {\"n_neighbors\":[3,5,7,9,11,13,15,17,19,21],\n",
    "          \"weights\":['uniform','distance'],\n",
    "          \"metric\":['euclidean','manhattan']}\n",
    "\n",
    "param2 = {'C': [0.1,1, 10, 100],\n",
    "          'gamma': [1,0.1,0.01,0.001],\n",
    "          'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "param3 = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "param4 = { 'criterion':['gini','entropy'],\n",
    "          'max_depth': np.arange(3, 15)}\n",
    "\n",
    "param5 = {'penalty': ['l1', 'l2'],\n",
    "          'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "\n",
    "param6 = {\n",
    "    'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "}\n",
    "\n",
    "#creating list of parameters\n",
    "model_param =[param1, param2, param3, param4 , param5 , param6]\n",
    "\n",
    "#Creating a string names for all the models, later used to campare model performance\n",
    "model_log = [\"_knn\", \"_svm\", \"_rf\", \"_dt\" , \"_lr\" , \"_gnb\"]\n",
    "\n",
    "#creating empty df\n",
    "Grid_knn = Grid_svm = Grid_rf = Grid_dt = Grid_lr = Grid_gnb = pd.DataFrame()\n",
    "\n",
    "#######################GridSearch-Cross_Validation function#################\n",
    "#Part-7\n",
    "#creating k-fold of 10\n",
    "for i in range(len(model_all)):\n",
    "    Grid=GridSearchCV(estimator=model_all[i], param_grid=model_param[i], \n",
    "                      n_jobs=-1, cv=10, verbose=3 ).fit(X,Y)\n",
    "    globals()['Grid%s' % model_log[i]]=pd.DataFrame(Grid.cv_results_)\n",
    "\n",
    "    '''above loop creates dataframes for all possible combinations of models having columns named mean test scores \n",
    "and ranking(ranking for mean test scores) '''\n",
    "\n",
    "#selecting rank 1 model in each dataset\n",
    "best_knn = Grid_knn[['mean_test_score' , 'rank_test_score']].query('rank_test_score== 1')\n",
    "best_svm = Grid_svm[['mean_test_score' , 'rank_test_score']].query('rank_test_score== 1')\n",
    "best_rf = Grid_rf[['mean_test_score' , 'rank_test_score']].query('rank_test_score== 1')\n",
    "best_dt = Grid_dt[['mean_test_score' , 'rank_test_score']].query('rank_test_score== 1')\n",
    "best_lr = Grid_lr[['mean_test_score' , 'rank_test_score']].query('rank_test_score== 1')\n",
    "best_gnb = Grid_gnb[['mean_test_score' , 'rank_test_score']].query('rank_test_score== 1')\n",
    "\n",
    "#printing test accuracy for all best models\n",
    "print(\"Test accuracy for best KNeighborsClassifier model:\",format(100*best_knn.iloc[0,0],\".2f\"),\"%\")\n",
    "print(\"Test accuracy for best SVC model:\",format(100*best_svm.iloc[0,0],\".2f\"),\"%\")\n",
    "print(\"Test accuracy for best RandomForestClassifier model:\",format(100*best_rf.iloc[0,0],\".2f\"),\"%\")\n",
    "print(\"Test accuracy for best DecisionTreeClassifier model:\",format(100*best_dt.iloc[0,0],\".2f\"),\"%\")\n",
    "print(\"Test accuracy for best LogisticRegression model:\",format(100*best_lr.iloc[0,0],\".2f\"),\"%\")\n",
    "print(\"Test accuracy for best GaussianNB model:\",format(100*best_gnb.iloc[0,0],\".2f\"),\"%\")\n",
    "\n",
    "# Models with their respective Accuracy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores=cross_val_score(LogisticRegression(), X, Y, cv=10)\n",
    "print(min(scores))\n",
    "print(max(scores))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d3017-877f-4767-ac01-3e51e5686525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
